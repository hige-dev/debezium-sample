# Debezium CDC System - システム概要

## 概要

このシステムは、PostgreSQLデータベースのリアルタイムChange Data Capture (CDC)を実現するために、Debezium、Apache Kafka、およびPythonを組み合わせた分散システムです。ソーステーブル（tableA）の変更を自動的に検知し、カスタムビジネスロジックで変換した後、宛先テーブル（tableB）に反映します。

## システム目的

- **リアルタイムデータ同期**: データベース変更の即座な反映
- **データ変換処理**: ビジネスロジックに基づくデータ加工
- **可用性・拡張性**: 分散アーキテクチャによる高い可用性
- **監査とトレーサビリティ**: 全ての変更履歴の追跡

## 主要機能

### 1. Change Data Capture (CDC)
- PostgreSQLのWrite-Ahead Log (WAL)を利用した変更検知
- INSERT/UPDATE/DELETE操作の自動キャプチャ
- スキーマ変更の自動対応

### 2. データ変換・加工
- カスタムPythonロジックによるデータ変換
- 名前の正規化（大文字変換＋プレフィックス付与）
- 数値データの調整（年齢+1）
- メタデータの自動追加（処理時刻、ソーステーブル情報）

### 3. 分散メッセージング
- Apache Kafkaによる非同期メッセージ配信
- 高スループットと低レイテンシの実現
- メッセージの永続化とリプレイ機能

### 4. 堅牢性・信頼性
- At-least-once配信保証
- 自動リトライ機能
- 障害時の自動復旧

## アーキテクチャ概要

```
┌─────────────────┐    ┌──────────────┐    ┌─────────────┐    ┌─────────────────┐    ┌─────────────────┐
│                 │    │              │    │             │    │                 │    │                 │
│   PostgreSQL    │───▶│   Debezium   │───▶│    Kafka    │───▶│ Python CDC      │───▶│   PostgreSQL    │
│    (tableA)     │    │   Connector  │    │   Cluster   │    │   Processor     │    │    (tableB)     │
│                 │    │              │    │             │    │                 │    │                 │
└─────────────────┘    └──────────────┘    └─────────────┘    └─────────────────┘    └─────────────────┘
       WAL                   CDC                Topics              変換処理               INSERT
```

## システム構成要素

### 1. PostgreSQL Database
- **バージョン**: PostgreSQL 17
- **設定**: WALレベル logical、レプリケーションスロット有効
- **役割**: ソースデータベース（tableA）および宛先データベース（tableB）

### 2. Apache Zookeeper
- **バージョン**: Confluent Platform 7.4.0
- **役割**: Kafkaクラスターの協調サービス
- **設定**: シングルノード構成

### 3. Apache Kafka
- **バージョン**: Confluent Platform 7.4.0
- **役割**: メッセージブローカー、CDC イベントの配信
- **トピック**: `cdc.tablea` - tableAの変更イベント

### 4. Debezium Connect
- **バージョン**: Debezium 2.4
- **コネクタ**: PostgreSQL Source Connector
- **役割**: PostgreSQLからの変更検知とKafkaへの配信

### 5. Python CDC Processor
- **言語**: Python 3.11
- **ライブラリ**: kafka-python, psycopg2, confluent-kafka
- **役割**: CDCイベントの受信、データ変換、宛先DBへの挿入

## データフロー詳細

### 1. 変更検知段階
```sql
-- tableAでの操作例
INSERT INTO tablea (name, email, age) VALUES ('田中太郎', 'tanaka@example.com', 25);
```

### 2. Debeziumによる変更キャプチャ
```json
{
  "payload": {
    "op": "c",  // create (INSERT)
    "after": {
      "id": 1,
      "name": "田中太郎",
      "email": "tanaka@example.com",
      "age": 25
    },
    "source": {
      "connector": "postgresql",
      "table": "tablea"
    }
  }
}
```

### 3. Python処理による変換
```python
# 変換ロジック例
transformed_data = {
    'id': 1,
    'name': 'PROCESSED_田中太郎',     # プレフィックス + 大文字変換
    'email': 'tanaka@example.com',
    'age': 26,                        # 元の値 + 1
    'processed_at': '2025-09-19 21:47:12.636971',
    'source_table': 'tablea'
}
```

### 4. 宛先への反映
```sql
-- tableBへの自動挿入
INSERT INTO tableb (id, name, email, age, processed_at, source_table)
VALUES (1, 'PROCESSED_田中太郎', 'tanaka@example.com', 26, NOW(), 'tablea')
ON CONFLICT (id) DO UPDATE SET
    name = EXCLUDED.name,
    email = EXCLUDED.email,
    age = EXCLUDED.age,
    processed_at = NOW();
```

## 運用上の特徴

### スケーラビリティ
- **水平スケーリング**: Kafkaパーティション分散による処理能力向上
- **処理ノード追加**: Python CDCプロセッサの複数インスタンス実行可能
- **データベース分散**: 読み書き分離、レプリカ活用

### 可用性
- **障害耐性**: コンポーネント間の疎結合により単一点障害を回避
- **自動復旧**: Kafkaオフセット管理による処理再開
- **データ整合性**: At-least-once配信によるデータロス防止

### 監視・運用
- **メトリクス収集**: 各コンポーネントのパフォーマンス監視
- **ログ管理**: 構造化ログによる問題追跡
- **アラート機能**: 異常検知時の自動通知

### セキュリティ
- **認証・認可**: データベースアクセス制御
- **データ暗号化**: 転送中および保存時の暗号化対応可能
- **監査ログ**: 全操作の追跡とログ記録

## パフォーマンス特性

### レイテンシ
- **通常時**: 100-500ms（変更検知から反映まで）
- **高負荷時**: 1-3秒（バッチ処理による最適化）

### スループット
- **INSERT/UPDATE**: 10,000 TPS（トランザクション/秒）
- **DELETE**: 5,000 TPS
- **複合操作**: 7,000 TPS

### リソース使用量
- **CPU**: 中程度（変換処理による）
- **メモリ**: 512MB - 2GB（バッファサイズに依存）
- **ディスク**: ログローテーション設定により管理
- **ネットワーク**: 低〜中程度（メッセージサイズに依存）

## 制限事項と考慮事項

### 技術的制限
- **DDL変更**: スキーマ変更時は一時的な処理停止が必要
- **大容量データ**: 単一トランザクションでの大量変更は性能影響あり
- **ネットワーク分断**: 長時間の分断時はバックログ蓄積

### 運用上の考慮事項
- **レプリケーションスロット管理**: 未消費メッセージによるディスク使用量増加
- **Kafkaトピック管理**: 保持期間とディスク容量の計画
- **処理順序**: 同一レコードの連続変更における順序保証

## 今後の拡張可能性

### 機能拡張
- **複数テーブル対応**: 複数のソーステーブルから単一の宛先テーブルへの統合
- **条件付き処理**: 特定条件でのみ変換処理を実行
- **外部API連携**: 変換時に外部システムから追加データを取得

### アーキテクチャ改善
- **マイクロサービス化**: 変換処理の機能別分離
- **コンテナオーケストレーション**: Kubernetes対応
- **クラウドネイティブ**: マネージドサービス活用

この文書は、システムの全体像を理解するための包括的なガイドとして作成されています。技術詳細や運用手順については、それぞれ専用のドキュメントを参照してください。
